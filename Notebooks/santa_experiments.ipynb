{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from os import getcwd\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/gifts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = df['Latitude'].to_numpy(np.float64)\n",
    "x2 = df['Longitude'].to_numpy(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating K-means cluster\n",
    "find out optimal number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x1 = df['Latitude'].to_numpy(np.float64)\n",
    "x2 = df['Longitude'].to_numpy(np.float64)\n",
    "\n",
    "plt.plot()\n",
    "plt.xlim([0, 10])\n",
    "plt.ylim([0, 10])\n",
    "plt.title('Dataset')\n",
    "plt.scatter(x1, x2)\n",
    "plt.show()\n",
    "\n",
    "# create new plot and data\n",
    "plt.plot()\n",
    "X = np.array(list(zip(x1, x2))).reshape(len(x1), 2)\n",
    "colors = ['b', 'g', 'r']\n",
    "markers = ['o', 'v', 's']\n",
    "\n",
    "# k means determine k\n",
    "distortions = []\n",
    "K = range(1,100)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(X)\n",
    "    kmeanModel.fit(X)\n",
    "    distortions.append(sum(np.min(cdist(X, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0])\n",
    "\n",
    "# Plot the elbow\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "\n",
    "df_coordinates=df[['Latitude','Longitude']]\n",
    "\n",
    "m = KMeans(n_clusters=20, n_init=3, max_iter=3000, random_state=1)\n",
    "#m = KMeans(20)\n",
    "m.fit(df_coordinates)\n",
    "\n",
    "df_coordinates['cl'] = m.labels_\n",
    "df_coordinates.sort_values(by=['cl'], inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "sns.scatterplot(data=df_coordinates, x=\"Longitude\", y=\"Latitude\", hue=\"cl\", size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coordinates.plot.scatter('Longitude', 'Latitude', c='cl', colormap='gist_rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Number of rows : \", len(df))\n",
    "print(\" \")\n",
    "print(\"Min Weight: \", df.Weight.min())\n",
    "print(\"Max Weight: \", df.Weight.max())\n",
    "\n",
    "print(\"Min Longitude: \",df.Longitude.min())\n",
    "print(\"Max Longitude: \",df.Longitude.max())\n",
    "print(\"Min Latitude: \",df.Latitude.min())\n",
    "print(\"Max Latitude: \",df.Latitude.max())\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 20, 10\n",
    "plt.hist2d(df.Longitude, df.Latitude, bins=360)\n",
    "cb = plt.colorbar()\n",
    "cb.set_label(\"density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['Weight'], bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harvesine Distance\n",
    "\n",
    "- extract lat & lon\n",
    "- stack values into np.array\n",
    "- reshape np.array to (-1,2)\n",
    "- convert lat & lon to radians\n",
    "- compute pairwise harvesine distance using sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic examples (Sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. using lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from math import radians\n",
    "\n",
    "bsas = [-34.83333, -58.5166646]\n",
    "paris = [49.0083899664, 2.53844117956]\n",
    "london = [51.5074, 0.1278]\n",
    "\n",
    "bsas_in_radians = [radians(_) for _ in bsas]\n",
    "paris_in_radians = [radians(_) for _ in paris]\n",
    "london_in_radians = [radians(_) for _ in london]\n",
    "\n",
    "print(bsas_in_radians)\n",
    "print(paris_in_radians)\n",
    "print(london_in_radians)\n",
    "result = haversine_distances([bsas_in_radians, paris_in_radians,london_in_radians])\n",
    "result * 6371000/1000  # multiply by Earth radius to get kilometers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. using np.arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsas = [-34.83333, -58.5166646]\n",
    "paris = [49.0083899664, 2.53844117956]\n",
    "london = [51.5074, 0.1278]\n",
    "\n",
    "cities = np.array([bsas,paris,london])\n",
    "cities_radian = np.radians(cities)\n",
    "result = haversine_distances(cities_radian)\n",
    "result * 6371000/1000  # multiply by Earth radius to get kilometers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas and Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first number is always the latitude and the second is the longitude ;)\n",
    "coords = df[['Latitude','Longitude']].head(10).to_numpy()\n",
    "coords = np.radians(coords)\n",
    "result = haversine_distances(coords)\n",
    "result * 6371000/1000  # multiply by Earth radius to get kilomet\n",
    "#df['Latitude'] = coords[:,0]\n",
    "#df['Longitude'] = coords[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Not to calculate pairwise distance between all locations..\n",
    "- The adj. Matrix of the complet craph would need n**2 * np.float memory\n",
    "- As calculated below, this would not be wise :D but for each tour it would be no problem (mean weight = 14.xx --> 70 stops on a maximum capacity of 1000) \n",
    "- Nevertheless, it could be useful to just transform the coordinates into radians anyway. That way, it wouldn't be necessary to do the calculations each time a sample is used for the weighted reindeer wearniess..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mat_size = len(df)\n",
    "print(\"Adj Matrix dimension: (\" ,adj_mat_size,\",\",adj_mat_size,\")\")\n",
    "print(\"Memory needed (GB):\", (adj_mat_size**2)*8/10**9 ) # roughly 8 bytes for a float in numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted reindeer weariness\n",
    "\n",
    "$$WRW = \\sum\\limits_{j=1}^{m} \\sum\\limits_{i=1}^{n} \\Big[ \\big( \\sum\\limits_{k=1}^{n} w_{kj} - \\sum\\limits_{k=1}^{i} w_{kj} \\big) \\cdot Dist(Loc_i, Loc_{i-1}) \\Big]_j ,$$\n",
    "\n",
    "$$m := \\text{number of trips} $$\n",
    "$$j := \\text{one specific trip}$$\n",
    "$$n := \\text{nmber of gifts (per trip j) }$$\n",
    "$$w_{ij} := \\text{weight of the }i^{th} \\text{ gift at trip j}$$ \n",
    "$$Loc_{0}\\text{ and } Loc_{0} \\text{is the north pole for each trip j}$$ \n",
    "$$w_{nj} := \\text{is the weight of the empty sled}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Example\n",
    "Example with the first ten entries:\n",
    "- trip 1 = entries 0:4\n",
    "- trip 2 = entries 5:9\n",
    "\n",
    "trip1 : North_Pole --> 0 --> 1 --> 2 --> 3 --> 4 --> North_Pole\\\n",
    "trip2 : North_Pole --> 5 --> 6 --> 7 --> 8 --> 9 --> North_Pole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_reindeer_weariness(trips):\n",
    "    weighted_weariness = 0\n",
    "    for trip in trips:\n",
    "        weights = trip['Weight'].to_numpy()\n",
    "        coordinates = trip[['Latitude','Longitude']].to_numpy()\n",
    "        weighted_weariness = weighted_weariness + weighted_distance(coordinates,weights,sleigh_weight)\n",
    "    return weighted_weariness\n",
    "    \n",
    "def weighted_distance(coordinates,weights,sleigh_weight):\n",
    "    startweight = sleigh_weight + np.sum(weights)\n",
    "    if startweight > weight_limit:\n",
    "        return -1\n",
    "\n",
    "    north_pole = np.radians([90,0])\n",
    "    coords = np.vstack((north_pole,coordinates,north_pole))\n",
    "  \n",
    "    adj_matrix = haversine_distances(coords,np.roll(coords.copy(),-1,axis=0))\n",
    "    adj_matrix = adj_matrix * 6371 #6371000/1000\n",
    "    distances = np.diag(adj_matrix)[:-1]\n",
    "    \n",
    "    weights +=sleigh_weight\n",
    "    weights = np.append(weights,sleigh_weight)\n",
    "    weights = np.cumsum(weights[::-1])[::-1] # flip, cummulative sum, flip again\n",
    "\n",
    "    \"\"\"\n",
    "    print(coords)\n",
    "    for i in range(len(coords)-1):\n",
    "        print(haversine_distances([coords[i],coords[i+1]])[0][1]*6371)\n",
    "    \n",
    "    with np.printoptions(precision=3, suppress=True):\n",
    "        print(distances,2)\n",
    "    \"\"\"\n",
    "    weighted_dist = np.sum(weights*distances)\n",
    "    print(\"weighted_dist \",weighted_dist)\n",
    "\n",
    "\n",
    "    return weighted_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_reindeer_weariness(trips):\n",
    "    weighted_weariness = 0\n",
    "    for trip in trips:\n",
    "        weights = trip['Weight'].to_numpy()\n",
    "        coordinates = trip[['Latitude','Longitude']].to_numpy()\n",
    "        weighted_weariness = weighted_weariness + weighted_distance(coordinates,weights,sleigh_weight)\n",
    "    return weighted_weariness\n",
    "    \n",
    "def weighted_distance(coordinates,weights,sleigh_weight):\n",
    "    startweight = sleigh_weight + np.sum(weights)\n",
    "    if startweight > weight_limit:\n",
    "        return -1\n",
    "\n",
    "    north_pole = np.radians([90,0])\n",
    "    coords = np.vstack((north_pole,coordinates,north_pole))\n",
    "    \n",
    "    print(coords)\n",
    "    distances = []\n",
    "    for i in range(len(coords)-1):\n",
    "        distances.append(haversine_distances([coords[i],coords[i+1]])[0][1]*6371)\n",
    "    distances = np.array(distances)\n",
    "    #adj_matrix = haversine_distances(coords,np.roll(coords.copy(),-1,axis=0))\n",
    "    #adj_matrix = adj_matrix * 6371 #6371000/1000\n",
    "    #distances = np.diag(adj_matrix)[:-1]\n",
    "    \n",
    "    weights +=sleigh_weight\n",
    "    weights = np.append(weights,sleigh_weight)\n",
    "    weights = np.cumsum(weights[::-1])[::-1] # flip, cummulative sum, flip again\n",
    "    \n",
    "    weighted_dist = np.sum(weights*distances)\n",
    "    print(\"weighted_dist \",weighted_dist)\n",
    "    return weighted_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([11]*10)\n",
    "w = 10\n",
    "\n",
    "weights = np.append(a,w)\n",
    "weights = np.cumsum(weights[::-1])[::-1]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "weight_limit = 1000\n",
    "sleigh_weight = 10\n",
    "\n",
    "entries = df.head(10)\n",
    "trip1 = entries[:5].copy()\n",
    "trip2 = entries[5:].copy()\n",
    "\n",
    "trips = [trip1.copy(),trip2.copy()]\n",
    "\n",
    "WRW = weighted_reindeer_weariness(trips)\n",
    "print(\"Total Wariness: \", WRW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[  1.57079633   0.        ]\n",
    " [ 16.34576887   6.30354513]\n",
    " [ 12.49474931  28.62639556]\n",
    " [ 27.79461514  60.03249479]\n",
    " [ 44.42699238 110.11421611]\n",
    " [-69.85408841  87.94687788]\n",
    " [  1.57079633   0.        ]]\n",
    "weighted_dist  4998503.445827983\n",
    "[[  1.57079633   0.        ]\n",
    " [ 53.56796981 -71.35930809]\n",
    " [ 12.90258404  79.96694891]\n",
    " [ -6.29109889 -64.89175089]\n",
    " [ -2.68531605 111.08975819]\n",
    " [ 38.42886187 101.97367095]\n",
    " [  1.57079633   0.        ]]\n",
    "weighted_dist  6032121.714568638\n",
    "Total Wariness:  11030625.16039662"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Implementation\n",
    " This is a naive implementation of a graph assigning each of the n coordinate for a gift delivery as a unique tour id.\n",
    "- obviously it results in n tours which is far from optimal\n",
    "- the TourId is stored as a new column in the dataframe\n",
    "- I guess this could be a starting point for building a solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self, gifts,tourId_provided = False):\n",
    "        self.numEdges = 0\n",
    "        self.sort_gifts = False\n",
    "        #data = self.init_tours(gifts)\n",
    "        #self.tourgraph = pd.DataFrame(data)\n",
    "        if tourId_provided:\n",
    "            \"\"\"\n",
    "            Assuming that an initial list of gifts with \n",
    "            corresponding tourIds is available.\n",
    "            \"\"\"\n",
    "            self.tourgraph = gifts\n",
    "            self.sort_gifts = True\n",
    "        else:\n",
    "            \"\"\"\n",
    "            assuming that just the original df is given \n",
    "            --> Naive tourlist with n tours\n",
    "            \"\"\"\n",
    "            data = self.init_tours(gifts)\n",
    "            self.tourgraph = pd.DataFrame(data)\n",
    "        \n",
    "    def init_tours(self, gifts):\n",
    "        tripIds = np.arange(len(gifts))\n",
    "        gifts_copy = gifts.copy()\n",
    "        gifts_copy['TripId'] = tripIds\n",
    "        return gifts_copy\n",
    "    \n",
    "    def weighted_reindeer_weariness(self):\n",
    "        weighted_weariness = 0\n",
    "        tot_distance = 0\n",
    "        trips = self.tourgraph\n",
    "        grouped_trips = trips.groupby('TripId')\n",
    "      \n",
    "        for group_name, trip in grouped_trips:\n",
    "            if self.sort_gifts:\n",
    "                trip = trip.sort_values(['Latitude','Longitude'],ascending=False)\n",
    "            trip\n",
    "            weights = trip['Weight'].to_numpy()\n",
    "            coordinates = trip[['Latitude','Longitude']].to_numpy()\n",
    "            current_wearniess= self.weighted_distance(coordinates,weights)\n",
    "            weighted_weariness += current_wearniess \n",
    "\n",
    "        #print(\"weighted_weariness \",weighted_weariness)\n",
    "        return weighted_weariness\n",
    "    \n",
    "    def weighted_distance(self, coordinates, weights,weight_limit=1000,sleigh_weight=10):\n",
    "        startweight = sleigh_weight + np.sum(weights)\n",
    "        if startweight > weight_limit:\n",
    "            return -1\n",
    "\n",
    "        north_pole = np.radians([90,0])\n",
    "        coords = np.vstack((north_pole,np.radians(coordinates),north_pole))\n",
    "        print(\"coords (function)\",coords)\n",
    "        distances = []\n",
    "        for i in range(len(coords)-1):\n",
    "            distances.append(haversine_distances([coords[i],coords[i+1]])[0][1]*6371000/1000)\n",
    "            \n",
    "        distances = np.array(distances)\n",
    "        print(\"distances (function):\",distances)\n",
    "        #adj_matrix = haversine_distances(coords,np.roll(coords.copy(),-1,axis=0))\n",
    "        #adj_matrix = adj_matrix * 6371 #6371000/1000\n",
    "        #distances = np.diag(adj_matrix)[:-1]\n",
    "\n",
    "        #weights +=sleigh_weight\n",
    "        weights = np.append(weights,sleigh_weight)\n",
    "        weights = np.cumsum(weights[::-1])[::-1] # flip, cummulative sum, flip again\n",
    "        weighted_dist = np.sum(weights*distances)\n",
    "        \n",
    "        return weighted_dist\n",
    "\n",
    "    \n",
    "#graph = Graph(df.head(10))\n",
    "#tours = graph.tourgraph      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/gifts.csv')\n",
    "graph = Graph(df)\n",
    "weariness = graph.weighted_reindeer_weariness()\n",
    "weariness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output with n (number of gifts) tours: \n",
    "\n",
    "44314259640.59521"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "graph.weighted_reindeer_weariness(tours)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/4314259640.59521 * 4608298.715468244"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/gifts.csv')\n",
    "offset = 0.5\n",
    "slices = []\n",
    "for i in range(0,360):\n",
    "    j = i+0.5\n",
    "    slices.append(df[(df['Longitude']>(j-offset)) & (df['Longitude']<(j+offset))])\n",
    "    \n",
    "for s in slices[:5]:\n",
    "    s.plot.scatter('Longitude','Latitude')\n",
    "    s.describe()\n",
    "\n",
    "first_slice = slices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "X = first_slice[['Latitude','Longitude']]\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(X)\n",
    "labels = kmeans.labels_\n",
    "first_slice['cluster_labels'] = kmeans.labels_\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "groups = first_slice.groupby('cluster_labels')\n",
    "for group_name, group in groups:\n",
    "    sum_weight = group['Weight'].sum()\n",
    "    print(\"sum_weight \", sum_weight)\n",
    "\n",
    "\n",
    "\n",
    "s.plot.scatter('Longitude','Latitude')\n",
    "s.describe()\n",
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "sns.scatterplot(data=first_slice, x=\"Longitude\", y=\"Latitude\", hue='cluster_labels', size=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing and initial Tours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import functools as ft\n",
    "from collections import ChainMap\n",
    "\n",
    "def create_sclices(df):\n",
    "    slices = []\n",
    "    offset=0.5\n",
    "    for i in range(-180,181):\n",
    "        j = i+offset\n",
    "        slices.append(df[(df['Longitude']>=(j-offset)) & (df['Longitude']<(j+offset))])\n",
    "    return slices\n",
    "\n",
    "def convert_tour_dict_to_df(tours):\n",
    "    res = {} \n",
    "    for dict in tours: \n",
    "        for list in dict: \n",
    "            if list in res: \n",
    "                res[list] += (dict[list]) \n",
    "            else: \n",
    "                res[list] = dict[list] \n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "def append_location(tour,row,tripId):\n",
    "        tour['GiftId'].append(row['GiftId'])\n",
    "        tour['Latitude'].append(row['Latitude'])\n",
    "        tour['Longitude'].append(row['Longitude'])\n",
    "        tour['Weight'].append(row['Weight']) \n",
    "        tour['TripId'].append(tripId) \n",
    "        \n",
    "def create_tours_from_slices(slices_list):\n",
    "    slices = slices_list\n",
    "    tours = []\n",
    "    tripId = 0\n",
    "    \n",
    "    tour = {\"GiftId\" : [],\"Latitude\" : [],\"Longitude\" :[],\"Weight\" : [],\"TripId\":[]}\n",
    "\n",
    "    for s in slices:\n",
    "        for index,row in s.iterrows():\n",
    "            sum_current_tour = ft.reduce(lambda x,y:x+y,tour['Weight'],0) \n",
    "            if (sum_current_tour+row['Weight'])<=weight_limit:\n",
    "                append_location(tour,row,tripId)\n",
    "            else:\n",
    "                tripId +=1\n",
    "                sum_current_tour = 0\n",
    "                tours.append(tour.copy())\n",
    "                tour = {\"GiftId\" : [],\"Latitude\" : [],\"Longitude\" :[],\"Weight\" : [],\"TripId\":[]}\n",
    "                append_location(tour,row,tripId)\n",
    "                \n",
    "    tours.append(tour.copy())\n",
    "    tours = convert_tour_dict_to_df(tours)\n",
    "    return tours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(tours,tourId_provided = True)  \n",
    "weariness = graph.weighted_reindeer_weariness()\n",
    "\n",
    "print(weariness)\n",
    "print(100/44314259640.59521*weariness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_tour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Results\n",
    "1. Output with n tours\n",
    "2. Output using 1 degree sclices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "num_elements = 3\n",
    "example_tour = df.head(3).copy()\n",
    "example_tour['TripId']=[0,0,0]\n",
    "example_tour = example_tour.sort_values(['Latitude','Longitude'],ascending=False)\n",
    "\n",
    "\n",
    "north_pole = np.radians(np.array([90,0]))\n",
    "loc_a = np.radians(np.array([example_tour.iloc[0]['Latitude'],example_tour.iloc[0]['Longitude']]))\n",
    "loc_b = np.radians(np.array([example_tour.iloc[1]['Latitude'],example_tour.iloc[1]['Longitude']]))\n",
    "loc_c = np.radians(np.array([example_tour.iloc[2]['Latitude'],example_tour.iloc[2]['Longitude']]))\n",
    "\n",
    "\n",
    "\n",
    "distances = []\n",
    "\n",
    "distance_1 = haversine_distances([north_pole,loc_a])[0][1]*6371000/1000\n",
    "distance_2 = haversine_distances([loc_a,loc_b])[0][1]*6371000/1000\n",
    "distance_3 = haversine_distances([loc_b,loc_c])[0][1]*6371000/1000\n",
    "distance_4 = haversine_distances([loc_c,north_pole])[0][1]*6371000/1000\n",
    "\n",
    "\n",
    "print(distance_1,distance_2,distance_3,distance_4)\n",
    "\n",
    "weight_1 = np.sum(example_tour['Weight'])+10\n",
    "weight_2 = weight_1 - example_tour.iloc[0]['Weight']\n",
    "weight_3 = weight_2 - example_tour.iloc[1]['Weight']\n",
    "weight_4 = 10\n",
    "weights = np.array([weight_1,weight_2,weight_3,weight_4])\n",
    "print(\"weights 1\", weights)\n",
    "\n",
    "weariness = distance_1*weight_1+distance_2*weight_2+distance_3*weight_3+distance_4*weight_4\n",
    "print(\"wearness 1 : \",weariness)\n",
    "\n",
    "\n",
    "\n",
    "graph = Graph(example_tour,tourId_provided = True)  \n",
    "weariness_n = graph.weighted_reindeer_weariness()\n",
    "print(\"wearness 2 : \",weariness_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv('../data/gifts.csv')\n",
    "#graph = Graph(df,tourId_provided = False)  \n",
    "#weariness_n = graph.weighted_reindeer_weariness()\n",
    "print(\"1. output with n tours\", weariness_n)\n",
    "\n",
    "df = pd.read_csv('../data/gifts.csv')\n",
    "slices_list = create_sclices(df)\n",
    "tours = create_tours_from_slices(slices_list)\n",
    "graph = Graph(tours,tourId_provided = True)  \n",
    "weariness_slices = graph.weighted_reindeer_weariness()\n",
    "print(\"2. Output using 1 degree sclices : \", weariness_slices)\n",
    "\n",
    "print(\"  \")\n",
    "print(\"weariness difference : \", weariness_n-weariness_slices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"weariness difference : \", weariness_n-weariness_slices)\n",
    "print(1/weariness_n*weariness_slices)\n",
    "best_result = 12384507107.54550\n",
    "\n",
    "print(\"difference best result: \",best_result-weariness_slices)\n",
    "print(1/best_result*weariness_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

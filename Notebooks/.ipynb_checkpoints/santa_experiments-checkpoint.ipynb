{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from os import getcwd\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/gifts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = df['Latitude'].to_numpy(np.float64)\n",
    "x2 = df['Longitude'].to_numpy(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating K-means cluster\n",
    "find out optimal number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x1 = df['Latitude'].to_numpy(np.float64)\n",
    "x2 = df['Longitude'].to_numpy(np.float64)\n",
    "\n",
    "plt.plot()\n",
    "plt.xlim([0, 10])\n",
    "plt.ylim([0, 10])\n",
    "plt.title('Dataset')\n",
    "plt.scatter(x1, x2)\n",
    "plt.show()\n",
    "\n",
    "# create new plot and data\n",
    "plt.plot()\n",
    "X = np.array(list(zip(x1, x2))).reshape(len(x1), 2)\n",
    "colors = ['b', 'g', 'r']\n",
    "markers = ['o', 'v', 's']\n",
    "\n",
    "# k means determine k\n",
    "distortions = []\n",
    "K = range(1,100)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(X)\n",
    "    kmeanModel.fit(X)\n",
    "    distortions.append(sum(np.min(cdist(X, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0])\n",
    "\n",
    "# Plot the elbow\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "\n",
    "df_coordinates=df[['Latitude','Longitude']]\n",
    "\n",
    "m = KMeans(n_clusters=20, n_init=3, max_iter=3000, random_state=1)\n",
    "#m = KMeans(20)\n",
    "m.fit(df_coordinates)\n",
    "\n",
    "df_coordinates['cl'] = m.labels_\n",
    "df_coordinates.sort_values(by=['cl'], inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "sns.scatterplot(data=df_coordinates, x=\"Longitude\", y=\"Latitude\", hue=\"cl\", size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coordinates.plot.scatter('Longitude', 'Latitude', c='cl', colormap='gist_rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Number of rows : \", len(df))\n",
    "print(\" \")\n",
    "print(\"Min Weight: \", df.Weight.min())\n",
    "print(\"Max Weight: \", df.Weight.max())\n",
    "\n",
    "print(\"Min Longitude: \",df.Longitude.min())\n",
    "print(\"Max Longitude: \",df.Longitude.max())\n",
    "print(\"Min Latitude: \",df.Latitude.min())\n",
    "print(\"Max Latitude: \",df.Latitude.max())\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 20, 10\n",
    "plt.hist2d(df.Longitude, df.Latitude, bins=360)\n",
    "cb = plt.colorbar()\n",
    "cb.set_label(\"density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harvesine Distance\n",
    "\n",
    "- extract lat & lon\n",
    "- stack values into np.array\n",
    "- reshape np.array to (-1,2)\n",
    "- convert lat & lon to radians\n",
    "- compute pairwise harvesine distance using sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic examples (Sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. using lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from math import radians\n",
    "\n",
    "bsas = [-34.83333, -58.5166646]\n",
    "paris = [49.0083899664, 2.53844117956]\n",
    "london = [51.5074, 0.1278]\n",
    "\n",
    "bsas_in_radians = [radians(_) for _ in bsas]\n",
    "paris_in_radians = [radians(_) for _ in paris]\n",
    "london_in_radians = [radians(_) for _ in london]\n",
    "\n",
    "print(bsas_in_radians)\n",
    "print(paris_in_radians)\n",
    "print(london_in_radians)\n",
    "result = haversine_distances([bsas_in_radians, paris_in_radians,london_in_radians])\n",
    "result * 6371000/1000  # multiply by Earth radius to get kilometers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. using np.arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsas = [-34.83333, -58.5166646]\n",
    "paris = [49.0083899664, 2.53844117956]\n",
    "london = [51.5074, 0.1278]\n",
    "\n",
    "cities = np.array([bsas,paris,london])\n",
    "cities_radian = np.radians(cities)\n",
    "result = haversine_distances(cities_radian)\n",
    "result * 6371000/1000  # multiply by Earth radius to get kilometers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas and Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first number is always the latitude and the second is the longitude ;)\n",
    "coords = df[['Latitude','Longitude']].head(10).to_numpy()\n",
    "coords = np.radians(coords)\n",
    "result = haversine_distances(coords)\n",
    "result * 6371000/1000  # multiply by Earth radius to get kilomet\n",
    "#df['Latitude'] = coords[:,0]\n",
    "#df['Longitude'] = coords[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Not to calculate pairwise distance between all locations..\n",
    "- The adj. Matrix of the complet craph would need n**2 * np.float memory\n",
    "- As calculated below, this would not be wise :D but for each tour it would be no problem (mean weight = 14.xx --> 70 stops on a maximum capacity of 1000) \n",
    "- Nevertheless, it could be useful to just transform the coordinates into radians anyway. That way, it wouldn't be necessary to do the calculations each time a sample is used for the weighted reindeer wearniess..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mat_size = len(df)\n",
    "print(\"Adj Matrix dimension: (\" ,adj_mat_size,\",\",adj_mat_size,\")\")\n",
    "print(\"Memory needed (GB):\", (adj_mat_size**2)*8/10**9 ) # roughly 8 bytes for a float in numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted reindeer weariness\n",
    "\n",
    "$$WRW = \\sum\\limits_{j=1}^{m} \\sum\\limits_{i=1}^{n} \\Big[ \\big( \\sum\\limits_{k=1}^{n} w_{kj} - \\sum\\limits_{k=1}^{i} w_{kj} \\big) \\cdot Dist(Loc_i, Loc_{i-1}) \\Big]_j ,$$\n",
    "\n",
    "$$m := \\text{number of trips} $$\n",
    "$$j := \\text{one specific trip}$$\n",
    "$$n := \\text{nmber of gifts (per trip j) }$$\n",
    "$$w_{ij} := \\text{weight of the }i^{th} \\text{ gift at trip j}$$ \n",
    "$$Loc_{0}\\text{ and } Loc_{0} \\text{is the north pole for each trip j}$$ \n",
    "$$w_{nj} := \\text{is the weight of the empty sled}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Example\n",
    "Example with the first ten entries:\n",
    "- trip 1 = entries 0:4\n",
    "- trip 2 = entries 5:9\n",
    "\n",
    "trip1 : North_Pole --> 0 --> 1 --> 2 --> 3 --> 4 --> North_Pole\\\n",
    "trip2 : North_Pole --> 5 --> 6 --> 7 --> 8 --> 9 --> North_Pole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_reindeer_weariness(trips):\n",
    "    weighted_weariness = 0\n",
    "    for trip in trips:\n",
    "        weights = trip['Weight'].to_numpy()\n",
    "        coordinates = trip[['Latitude','Longitude']].to_numpy()\n",
    "        weighted_weariness = weighted_weariness + weighted_distance(coordinates,weights,sleigh_weight)\n",
    "    return weighted_weariness\n",
    "    \n",
    "def weighted_distance(coordinates,weights,sleigh_weight):\n",
    "    startweight = sleigh_weight + np.sum(weights)\n",
    "    if startweight > weight_limit:\n",
    "        return -1\n",
    "\n",
    "    north_pole = np.radians([90,0])\n",
    "    coords = np.vstack((north_pole,coordinates,north_pole))\n",
    "  \n",
    "    adj_matrix = haversine_distances(coords,np.roll(coords.copy(),-1,axis=0))\n",
    "    adj_matrix = adj_matrix * 6371 #6371000/1000\n",
    "    distances = np.diag(adj_matrix)[:-1]\n",
    "    \n",
    "    weights +=sleigh_weight\n",
    "    weights = np.append(weights,sleigh_weight)\n",
    "    weights = np.cumsum(weights[::-1])[::-1] # flip, cummulative sum, flip again\n",
    "\n",
    "    \"\"\"\n",
    "    print(coords)\n",
    "    for i in range(len(coords)-1):\n",
    "        print(haversine_distances([coords[i],coords[i+1]])[0][1]*6371)\n",
    "    \n",
    "    with np.printoptions(precision=3, suppress=True):\n",
    "        print(distances,2)\n",
    "    \"\"\"\n",
    "    weighted_dist = np.sum(weights*distances)\n",
    "    print(\"weighted_dist \",weighted_dist)\n",
    "\n",
    "\n",
    "    return weighted_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "weight_limit = 1000\n",
    "sleigh_weight = 10\n",
    "\n",
    "entries = df.head(10)\n",
    "trip1 = entries[:5].copy()\n",
    "trip2 = entries[5:].copy()\n",
    "\n",
    "trips = [trip1.copy(),trip2.copy()]\n",
    "\n",
    "WRW = weighted_reindeer_weariness(trips)\n",
    "print(\"Total Wariness: \", WRW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
